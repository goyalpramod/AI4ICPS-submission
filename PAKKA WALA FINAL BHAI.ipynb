{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "ca42f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "27e08e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87053a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
    "train_df = pd.read_csv(\"train (1).csv\")\n",
    "test_df = pd.read_csv(\"test (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7c2acb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns={'Id','Property_A','Property_B','Property_C','Property_D','Property_E','Property_F'})\n",
    "y_train = train_df[['Property_A','Property_B','Property_C','Property_D','Property_E','Property_F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3efcad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1_X_train = X_train[['A ','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "fb622b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor1_X_test = test_df[['A ','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ef8fb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor2_X_train = X_train.drop(columns={'A ','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "f435d80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor2_X_test = test_df.drop(columns={'A ','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Id'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df5dddf",
   "metadata": {},
   "source": [
    "# Predicting Individual classes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f301e",
   "metadata": {},
   "source": [
    "## Predicting a first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "82b41ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a_sensor1 = sensor1_X_train[['B','D','G','H','I','J','K','L','N']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ca235a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_a = y_train['Property_A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "4a7de457",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a_sensor2 = sensor2_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d26121f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_a_together = pd.concat([x_train_a_sensor1, x_train_a_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4072cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a_sensor1 =  sensor1_X_test[['B','D','G','H','I','J','K','L','N']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "940f9a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a_sensor2 = sensor2_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e9e6c21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_a_together = pd.concat([x_test_a_sensor1, x_test_a_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2399775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_a_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_a_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_a_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "2abb9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "949424e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_a, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0ca88315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of base models\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('random forest' , RandomForestRegressor(n_estimators=38,max_depth=10, random_state=0)))\n",
    "    models.append(('xbg', xgb.XGBRegressor()))\n",
    "    models.append(('lgm', lgm.LGBMRegressor()))\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8f3136e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate each base model\n",
    "def evaluate_models(models, X_train, X_val, y_train, y_val):\n",
    " # fit and evaluate the models\n",
    "    scores = list()\n",
    "    for name, model in models:\n",
    " # fit the model\n",
    "        model.fit(X_train, y_train)\n",
    " # evaluate the model\n",
    "        yhat = model.predict(X_val)\n",
    "        mse = mean_squared_error(y_val, yhat)\n",
    " # store the performance\n",
    "        scores.append(mse)\n",
    " # report model performance\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "92dab94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17207977146769973, 0.22100050126939502, 0.19150369218147353]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_a)\n",
    "# make predictions on test set\n",
    "yhat_a = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490c4ec9",
   "metadata": {},
   "source": [
    "## Predicting b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1384f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_b_sensor1 = sensor1_X_train[['C','D','L','M','N','O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "245cce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_b = y_train['Property_B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d2fe1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_b_sensor2 = sensor2_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8cdaa94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_b_together = pd.concat([x_train_b_sensor1, x_train_b_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d6ef9a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_b_sensor1 =  sensor1_X_test[['C','D','L','M','N','O']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5663b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_b_sensor2 = sensor2_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "03aa6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_b_together = pd.concat([x_test_b_sensor1, x_test_b_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8f3326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_b_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_b_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_b_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ed1b6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "266fa48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_b, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "6e95028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7439186269813826, 0.5757829792537359, 0.5353211055927855]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_b)\n",
    "# make predictions on test set\n",
    "yhat_b = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc81815",
   "metadata": {},
   "source": [
    "## Predicting c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "356abe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c_sensor1 = sensor1_X_train[['B','C','D','F','H','I','J','K','L','M','N']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "363bbb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_c = y_train['Property_C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f311a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = sensor2_X_train.columns\n",
    "\n",
    "list_3 = []\n",
    "\n",
    "for i in list_1:\n",
    "    if int(i[:4]) in range(550,600):\n",
    "        list_3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "94b1808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c_sensor2 = sensor2_X_train[list_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1a745d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_c_together = pd.concat([x_train_c_sensor1, x_train_c_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5584af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_c_sensor1 =  sensor1_X_test[['B','C','D','F','H','I','J','K','L','M','N']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "4f829222",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_c_sensor2 = sensor2_X_test[list_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "78d43a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_c_together = pd.concat([x_test_c_sensor1, x_test_c_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "533c32a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_c_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_c_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_c_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a4f03c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1d34f448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_c, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8ad015f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0711975085875399, 0.07555883993661283, 0.09705616926554332]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_c)\n",
    "# make predictions on test set\n",
    "yhat_c = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7975131f",
   "metadata": {},
   "source": [
    "## Predicting d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d31a802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_d_sensor1 = sensor1_X_train[['C','D','E','M','N','O','P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "47b07ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_d = y_train['Property_D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f8a5844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_d_sensor2 = sensor2_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e534e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_d_together = pd.concat([x_train_d_sensor1, x_train_d_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "bab5e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_d_sensor1 =  sensor1_X_test[['C','D','E','M','N','O','P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "4c62972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_d_sensor2 = sensor2_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "60768601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_d_together = pd.concat([x_test_d_sensor1, x_test_d_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2399775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_d_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_d_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_d_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2abb9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7c42fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_d, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "9331a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.47406363915752, 66.7759448878805, 97.72427955395607]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_d)\n",
    "# make predictions on test set\n",
    "yhat_d = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f61ff8",
   "metadata": {},
   "source": [
    "## Predicting e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cda790f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_e_sensor1 = sensor1_X_train[['B','C','D','G','H','I','J','M','N','O','P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "472f5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = y_train['Property_E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c99cdd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = sensor2_X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b1e057db",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_4 = []\n",
    "\n",
    "for i in list_1:\n",
    "    if int(i[:4]) in range(350,450):\n",
    "        list_4.append(i)\n",
    "\n",
    "for i in list_1:\n",
    "    if int(i[:4]) in range(800,1850):\n",
    "        list_4.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "1912e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_e_sensor2 = sensor2_X_train[list_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "cff0c3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_e_together = pd.concat([x_train_e_sensor1, x_train_e_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "0dcfd057",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_e_sensor1 =  sensor1_X_test[['B','C','D','G','H','I','J','M','N','O','P']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "58b24390",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_e_sensor2 = sensor2_X_test[list_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "fc9fb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_e_together = pd.concat([x_test_e_sensor1, x_test_e_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2399775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_e_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_e_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_e_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2abb9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "0a368bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_e, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "46ef1fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86.21591354496412, 136.42489000145306, 93.56655344043632]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_e)\n",
    "# make predictions on test set\n",
    "yhat_e = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38b415b",
   "metadata": {},
   "source": [
    "## Predicting f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "c739e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f_sensor1 = sensor1_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a722d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_f = y_train['Property_F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "88de90b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f_sensor2 = sensor2_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "96b36fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_f_together = pd.concat([x_train_f_sensor1, x_train_f_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "fa5e127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_f_sensor1 =  sensor1_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "fbda5843",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_f_sensor2 = sensor2_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bf3942b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_f_together = pd.concat([x_test_f_sensor1, x_test_f_sensor2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2399775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# fit scaler on training data\n",
    "norm = MinMaxScaler().fit(x_train_f_together)\n",
    "\n",
    "# transform training data\n",
    "X_train_norm = norm.transform(x_train_f_together)\n",
    "X_train_norm_df = pd.DataFrame(X_train_norm)\n",
    "\n",
    "# transform testing dataabs\n",
    "X_test_norm = norm.transform(x_test_f_together)\n",
    "X_test_norm_df = pd.DataFrame(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2abb9fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Standardize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scalar = StandardScaler()\n",
    " \n",
    "# fitting\n",
    "scalar.fit(X_train_norm_df)\n",
    "X_train_stan = scalar.transform(X_train_norm_df)\n",
    "X_train_stan_df = pd.DataFrame(X_train_stan)\n",
    "\n",
    "scalar.fit(X_test_norm_df)\n",
    "X_test_stan = scalar.transform(X_test_norm_df)\n",
    "X_test_stan_df = pd.DataFrame(X_test_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "01d973c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_train_stan_df, y_train_f, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "134080aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19.481367732055507, 30.583875908862066, 22.549348865009982]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "models = get_models()\n",
    "# fit and evaluate each model\n",
    "scores = evaluate_models(models, X_train_3, X_test_3, y_train_3, y_test_3)\n",
    "print(scores)\n",
    "# create the ensemble\n",
    "ensemble = VotingRegressor(estimators=models, weights=scores)\n",
    "# fit the ensemble on the training dataset\n",
    "ensemble.fit(X_train_stan_df, y_train_f)\n",
    "# make predictions on test set\n",
    "yhat_f = ensemble.predict(X_test_stan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "7549f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = yhat_a+yhat_b+yhat_c+yhat_e+yhat_d+yhat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1855d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_store_df = pd.DataFrame(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "22ccd66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_id = test_df['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "bd8df88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test_df_id, temp_store_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "a1cb4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.rename({0:\"Predicted\"},axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8a31917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('file12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df031e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
